{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML to DL Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M_-9P5Ctd5U"
      },
      "source": [
        "# Library yang akan dipakai\n",
        "import zipfile\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D, AveragePooling2D, MaxPooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers.core import Dense, Dropout, Flatten\n",
        "\n",
        "# Untuk load data\n",
        "from imutils import paths\n",
        "from PIL import Image\n",
        "import argparse\n",
        "import matplotlib.pyplot as plt # untuk menampilkan contoh gambar/data dalam gambar\n",
        "\n",
        "# Untuk Data Loading -> yang membagi data\n",
        "from sklearn.preprocessing import LabelBinarizer # Untuk binarisasi label\n",
        "from sklearn.model_selection import train_test_split # Untuk ngesplit data train & test\n",
        "from sklearn.metrics import classification_report # Untuk performance measurement, untuk menghasilkan confusion matriks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrk83HuOrOWW",
        "outputId": "314cf43b-088f-4d18-f8fc-947130db8d6c"
      },
      "source": [
        "# Import data from GDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "Ws8p9MrHrc-U",
        "outputId": "d7ab8753-2e54-421a-cef7-eca954fb9fcc"
      },
      "source": [
        "# Extract the zip file\n",
        "\n",
        "local_zip = '/content/gdrive/MyDrive/Colab Notebooks/FGA/ML to DL Image Classification/Copy of 3scenes.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/gdrive/MyDrive/Colab Notebooks/FGA/ML to DL Image Classification/')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-bb84796da5aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlocal_zip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/gdrive/MyDrive/Colab Notebooks/FGA/ML to DL Image Classification/Copy of 3scenes.zip'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mzip_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_zip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/MyDrive/Colab Notebooks/FGA/ML to DL Image Classification/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36mextractall\u001b[0;34m(self, path, members, pwd)\u001b[0m\n\u001b[1;32m   1634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mzipinfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1636\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_member\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m_extract_member\u001b[0;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m              \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1691\u001b[0;31m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aww3gCLEs8Mv",
        "outputId": "aeaea19a-7a80-4e56-9ce3-589d6fcedd44"
      },
      "source": [
        "# Some stuffs from Dicoding\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "total_gen = ImageDataGenerator(\n",
        "                    validation_split=0.25,\n",
        "                    rescale=1./255)\n",
        "\n",
        "train_gen = total_gen\n",
        "train_gen.horizontal_flip = True\n",
        "train_gen.fill_mode = \"nearest\"\n",
        "\n",
        "train_generator = train_gen.flow_from_directory(\n",
        "                    '/content/gdrive/MyDrive/Colab Notebooks/FGA/ML to DL Image Classification/3scenes',\n",
        "                    target_size = (32,32),\n",
        "                    batch_size = 4,\n",
        "                    class_mode = 'categorical',\n",
        "                    subset = 'training'                    \n",
        "                    )\n",
        "validation_generator = total_gen.flow_from_directory(\n",
        "                    '/content/gdrive/MyDrive/Colab Notebooks/FGA/ML to DL Image Classification/3scenes',\n",
        "                    target_size = (32,32),\n",
        "                    batch_size = 4,\n",
        "                    class_mode = 'categorical',\n",
        "                    subset = 'validation'  \n",
        "                    )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 711 images belonging to 3 classes.\n",
            "Found 237 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "549IYOshvTyk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEYFx8ugxBii",
        "outputId": "85eccd23-3d9a-4be9-c9b9-b9c6147958a7"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(16, kernel_size = (3,3), strides = (1,1), padding = 'same', activation = 'relu', input_shape = (32,32 ,3)))\n",
        "model.add(AveragePooling2D(2,2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "model.add(Conv2D(32, kernel_size = (3,3), strides = (1,1), padding = 'same', activation = 'relu'))\n",
        "model.add(AveragePooling2D(2,2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "model.add(Conv2D(32, kernel_size = (3,3), strides = (1,1), padding = 'same', activation = 'relu'))\n",
        "model.add(AveragePooling2D(2,2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(3, activation = 'softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 32, 32, 16)        448       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_4 (Average (None, 16, 16, 16)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 16, 16, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 16, 16, 32)        4640      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_5 (Average (None, 8, 8, 32)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 32)          128       \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 8, 8, 32)          9248      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_6 (Average (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 4, 4, 32)          128       \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 1539      \n",
            "=================================================================\n",
            "Total params: 16,195\n",
            "Trainable params: 16,035\n",
            "Non-trainable params: 160\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_u2fT71y3Y5"
      },
      "source": [
        "# compile model dengan 'adam' optimizer loss function 'categorical_crossentropy' \n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.optimizers.Adam(learning_rate=1e-3, decay=1e-3 / 50),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Un3F95p5y9Xa",
        "outputId": "145d04d9-5355-47be-d1cf-6bcca1f2dd12"
      },
      "source": [
        "model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=25,  \n",
        "      epochs=50, \n",
        "      validation_data=validation_generator, # menampilkan akurasi pengujian data validasi\n",
        "      validation_steps=5,\n",
        "      verbose = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "25/25 [==============================] - 34s 1s/step - loss: 1.7503 - accuracy: 0.4200 - val_loss: 1.0811 - val_accuracy: 0.5500\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 29s 1s/step - loss: 0.8839 - accuracy: 0.6400 - val_loss: 1.0451 - val_accuracy: 0.5500\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 24s 968ms/step - loss: 0.7889 - accuracy: 0.6400 - val_loss: 1.0813 - val_accuracy: 0.5000\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 19s 752ms/step - loss: 0.5422 - accuracy: 0.7800 - val_loss: 1.0451 - val_accuracy: 0.4000\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 19s 777ms/step - loss: 0.6897 - accuracy: 0.7300 - val_loss: 1.0888 - val_accuracy: 0.4500\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 15s 601ms/step - loss: 0.4319 - accuracy: 0.8500 - val_loss: 0.8673 - val_accuracy: 0.6000\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 13s 532ms/step - loss: 0.5101 - accuracy: 0.7900 - val_loss: 1.2464 - val_accuracy: 0.3500\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 16s 671ms/step - loss: 0.5940 - accuracy: 0.7800 - val_loss: 1.0672 - val_accuracy: 0.5000\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 10s 431ms/step - loss: 0.6914 - accuracy: 0.7100 - val_loss: 0.8095 - val_accuracy: 0.6500\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 9s 364ms/step - loss: 0.5394 - accuracy: 0.7778 - val_loss: 0.9459 - val_accuracy: 0.5000\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 6s 230ms/step - loss: 0.4327 - accuracy: 0.8500 - val_loss: 1.1899 - val_accuracy: 0.5500\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 6s 265ms/step - loss: 0.4121 - accuracy: 0.8500 - val_loss: 0.8597 - val_accuracy: 0.6000\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 6s 249ms/step - loss: 0.4225 - accuracy: 0.8200 - val_loss: 0.7796 - val_accuracy: 0.7500\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 5s 181ms/step - loss: 0.5793 - accuracy: 0.7700 - val_loss: 1.3319 - val_accuracy: 0.5000\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 4s 166ms/step - loss: 0.3817 - accuracy: 0.8300 - val_loss: 0.8670 - val_accuracy: 0.5500\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 4s 139ms/step - loss: 0.5102 - accuracy: 0.7800 - val_loss: 0.7040 - val_accuracy: 0.8000\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 3s 125ms/step - loss: 0.4406 - accuracy: 0.7900 - val_loss: 0.9205 - val_accuracy: 0.6500\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 3s 132ms/step - loss: 0.3424 - accuracy: 0.8800 - val_loss: 0.3110 - val_accuracy: 0.9000\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 3s 103ms/step - loss: 0.3579 - accuracy: 0.8700 - val_loss: 0.7632 - val_accuracy: 0.8000\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 2s 90ms/step - loss: 0.4700 - accuracy: 0.8500 - val_loss: 0.5964 - val_accuracy: 0.8000\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.3603 - accuracy: 0.8700 - val_loss: 0.4949 - val_accuracy: 0.8000\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 2s 86ms/step - loss: 0.3502 - accuracy: 0.8600 - val_loss: 0.8269 - val_accuracy: 0.7500\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 2s 84ms/step - loss: 0.3135 - accuracy: 0.8800 - val_loss: 0.2491 - val_accuracy: 0.9500\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 2s 61ms/step - loss: 0.4396 - accuracy: 0.8600 - val_loss: 0.2951 - val_accuracy: 0.8500\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 2s 77ms/step - loss: 0.4263 - accuracy: 0.8800 - val_loss: 0.8033 - val_accuracy: 0.7500\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.2773 - accuracy: 0.9200 - val_loss: 0.8422 - val_accuracy: 0.7000\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 2s 86ms/step - loss: 0.4033 - accuracy: 0.8300 - val_loss: 0.5337 - val_accuracy: 0.9000\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 1s 38ms/step - loss: 0.4609 - accuracy: 0.8300 - val_loss: 0.3850 - val_accuracy: 0.8500\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3945 - accuracy: 0.8586 - val_loss: 0.0612 - val_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 0.3663 - accuracy: 0.8900 - val_loss: 0.1145 - val_accuracy: 0.9500\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3841 - accuracy: 0.8600 - val_loss: 3.6452 - val_accuracy: 0.3500\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.2559 - accuracy: 0.8900 - val_loss: 0.7640 - val_accuracy: 0.7500\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.2275 - accuracy: 0.9394 - val_loss: 0.3702 - val_accuracy: 0.9000\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.2509 - accuracy: 0.8900 - val_loss: 1.5971 - val_accuracy: 0.6000\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 2s 65ms/step - loss: 0.3827 - accuracy: 0.8100 - val_loss: 0.5685 - val_accuracy: 0.7000\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.4452 - accuracy: 0.8283 - val_loss: 7.9986 - val_accuracy: 0.3500\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 2s 66ms/step - loss: 0.3119 - accuracy: 0.8889 - val_loss: 1.3648 - val_accuracy: 0.7500\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 0.4288 - accuracy: 0.8600 - val_loss: 4.8047 - val_accuracy: 0.4500\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.3638 - accuracy: 0.8600 - val_loss: 1.0528 - val_accuracy: 0.6500\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 0.2539 - accuracy: 0.9300 - val_loss: 0.6719 - val_accuracy: 0.9000\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 0.3438 - accuracy: 0.8500 - val_loss: 0.9106 - val_accuracy: 0.8000\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 2s 82ms/step - loss: 0.3383 - accuracy: 0.8700 - val_loss: 0.1341 - val_accuracy: 0.9500\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 0.3926 - accuracy: 0.8700 - val_loss: 0.7250 - val_accuracy: 0.8000\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 1s 30ms/step - loss: 0.2810 - accuracy: 0.8900 - val_loss: 1.1187 - val_accuracy: 0.7000\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.2152 - accuracy: 0.9200 - val_loss: 0.7756 - val_accuracy: 0.7500\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.2290 - accuracy: 0.9300 - val_loss: 0.4827 - val_accuracy: 0.8500\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 1s 35ms/step - loss: 0.3518 - accuracy: 0.8800 - val_loss: 0.9380 - val_accuracy: 0.7500\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.4520 - accuracy: 0.8900 - val_loss: 0.8529 - val_accuracy: 0.6500\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 1s 30ms/step - loss: 0.2290 - accuracy: 0.9000 - val_loss: 0.3070 - val_accuracy: 0.9000\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.3227 - accuracy: 0.9000 - val_loss: 0.4209 - val_accuracy: 0.9000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f97bb4f5dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6qlpavlTKQG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgV_ZuVUAMpZ"
      },
      "source": [
        "Another way to Load Data in zipfile.\n",
        "\n",
        "**Development Case**\n",
        "\n",
        "\n",
        "Cari tau implemenetasi dalam pebuatan model gimana caranya.\n",
        "1. Menggunakan Notebook(bisa dianggap sebagai terminal, bisa dieksekusi baris perbaris) \n",
        "    Training dan Testing terdapat dalam 1 notebook(ipynb)\n",
        "\n",
        "    Notebook, Google Colab, IBM Watson, dll (Kebanyakan skrg file .ipynb)\n",
        "\n",
        "2. File Python\n",
        "    Untuk membuat untuk training dan testing dipisah (ex : training.py & testing.py)\n",
        "\n",
        "    Dirun dalam terminal(bisa lewat terminal/notebook) .py\n",
        "\n",
        "**Data Loading**\n",
        "Ada macam2 :\n",
        "1. Membaca data\n",
        "2. Membagi data menjadi data training dan data testing\n",
        "\n",
        "Data training bisa dibagi menjadi 2 , training & validation -> Data yang dipakai untuk proses training, dipakai untuk mengupdate model, weight.\n",
        "\n",
        "Data testing -> Dipakai untuk melihat performa dari model. Data ini belum pernah dipakai/dilihat oleh model\n",
        "\n",
        "Problem -> Gimana cara membagi datanya?\n",
        "1. Membagi data menjadi 2 folder terpisah untuk training dan testing, kalau belum?\n",
        "2. Cek di file bapanya https://colab.research.google.com/drive/1kYfi4njzcaQBx-18bpa-K5vcm5woQYJQ?usp=sharing#scrollTo=XQNvMZsuzZtp\n",
        "\n",
        "\n",
        "trainX, testX, trainY, testY\n",
        "\n",
        "X = gambar, Y = label\n",
        "\n",
        "**Cek juga drive bapanya**\n",
        "\n",
        "https://drive.google.com/drive/folders/18Y6NI8nN7Iu5wM8nnlUW0GFDlc0EWo_r?usp=sharing\n",
        "\n",
        "\n",
        "20/08/2021\n",
        "\n",
        "Didalam Deep Learning dibagi menjadi 2 bagian\n",
        "\n",
        "Feature Extraction Layer\n",
        "\n",
        "Pertama -> Extract Input, Pooling ,dsb\n",
        "\n",
        "Didalam Dense, ada 3 output(misal ada 3 kelas)\n",
        "\n",
        "RBG-D/RBG-T(RGB with thermal) Object Recognition using MultiModal Deep Neural Network(Search this Shit on Google)\n",
        "\n",
        "Object Detection -> pake image MS-COCO, suatu dataset, jumlah jutaan, udah ada pretrain weightnya juga. Terdapat 80 kelas\n",
        "\n",
        "Kita perlu tahu filosofi dari setiap setting dan di modifikasi isi modelnya\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXOwafRgQoJq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}